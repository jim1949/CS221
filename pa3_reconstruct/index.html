<head>
  <script src="plugins/main.js"></script>
  <title>Text reconstruction</title>

  <style type="text/css">
    .nl { font-family:monospace; }
  </style>
</head>

<script type="text/javascript">
  function _getLink() { return '<a href="http://cs.stanford.edu/~rfrostig/">Roy Frostig</a>' }
</script>
<body onload="onLoad('Will Harvey', 'Assignment by ' + _getLink())">

<div id="assignmentHeader"></div>

<p><img src="holykeys.png"/></p>

<p>
  In this homework, we consider two 
  tasks: <i>word segmentation</i> and <i>vowel insertion</i>.

  Word segmentation often comes up in processing many non-English
  languages, in which words might not be flanked by spaces on either
  end, such as in written Chinese or in long compound German
  words.<sup><a href="#fn-1">[1]</a></sup>

  Vowel insertion is relevant in languages such as Arabic or Hebrew,
  for example, where modern script eschews notations for vowel sounds
  and the human reader infers them from
  context.<sup><a href="#fn-2">[2]</a></sup> More generally, it is an
  instance of a reconstruction problem given lossy encoding and some
  context.
</p>
<p>
  We already know how to optimally solve any particular min-cost
  state-space search problem with graph search algorithms such as
  uniform cost search or A*.  Our goal here is modeling,
  converting real-world tasks into state-space search problems.
</p>

<!------------------------------------------------------------>
<div class="problemTitle">Setup: $n$-gram language models and
uniform-cost search</div>

<p>
  Our algorithm will base segmentation and insertion decisions based
  on the cost of produced text according to a <i>language model</i>.
  A language model is some function of the processed text that
  captures its fluency.
</p>

<p>
  A very common language model in NLP is an $n$-gram sequence model: a
  function that, given $n$ consecutive words, gives a cost based on
  to the negative likelihood that the $n$-th word appears just after the first
  $n-1$.<sup><a href="#fn-3">[3]</a></sup>

  The cost will always be positive, and lower costs indicate better
  fluency.<sup><a href="#fn-4">[4]</a></sup>
  As a simple example: in a case where $n=2$ and $c$ is our
  $n$-gram cost function, $c(\mathsf{big}, \mathsf{fish})$ would be
  low, but $c(\mathsf{fish}, \mathsf{fish})$ would be fairly high.
</p>
<p>
  Furthermore, these costs are additive: for a unigram model $u$ ($n = 1$),
  the cost assigned to $[w_1, w_2, w_3, w_4]$ is
 \[
   u(w_1) + u(w_2) + u(w_3) + u(w_4).
  \]

  For a bigram model $b$ ($n = 2$), the cost is
   \[
    b(w_0, w_1) +
    b(w_1, w_2) +
    b(w_2, w_3) +
    b(w_3, w_4),
  \]
  where $w_0$ is <code>-BEGIN-</code>, a special token that denotes the beginning of the sentence.
  We have estimated $u$ and $b$ based on the statistics of $n$-grams in text,
  so you do not have to worry about this part.
</p>

<p>
  A note on low-level efficiency and expectations: this assignment was
  designed considering input sequences of length no greater than
  roughly 200 (characters, or list items, depending on the task).  Of
  course, it's great if programs tractably manage larger inputs,
  but it isn't expected that such inputs not lead to inefficiency
  due to overwhelming state space growth.
</p>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 1: word segmentation</div>

<p>
  In word segmentation, you are given as input a string of
  alphabetical characters (<code>[a-z]</code>) without whitespace, and
  your goal is to insert spaces into this string such that the result
  is the most fluent according to the language model.
</p>

<ol class="problem">

<li class="writeup">
  <p>
  Consider the following greedy algorithm:
  Begin at the front of the string.  Find the
  ending position for the next word that minimizes the
  language model cost.
  Repeat, beginning at the end of this chosen segment.

  <p>
    Show that this greedy search is suboptimal.  In particular,
    provide an example input string on which the greedy approach would
    fail to find the lowest-cost segmentation of the input.
  </p>
  <p>
    In creating this example, you are free to design the $n$-gram cost
    function (both the choice of $n$ and the cost of any $n$-gram
    sequences) but costs must be positive and lower cost should
    indicate better fluency.  Your example should be based on a
    realistic English word sequence &mdash; don't simply use abstract
    symbols with designated costs.
  </p>
</li>

<li class="code">
  <p>
    Implement an algorithm that, unlike greedy, finds the optimal word
    segmentation of an input character sequence.  Your algorithm
    will consider costs based simply on a unigram cost function.
  </p>
  <p>
    Before jumping into code, you should think about how to frame
    this problem as a state-space search problem.  How would you
    represent a state?  What are the successors of a state?  What are
    the state transition costs?  (You don't need to answer these
    questions in your writeup.)
  </p>
  <p>
    Uniform
    cost search (UCS) is implemented for you, and you should make use of
    it here.<sup><a href="#fn-5">[5]</a></sup>
  </p>
  <p>
    Fill in the member functions of
    the <code>SegmentationProblem</code> class and
    the <code>segmentWords</code> function.

    The argument <code>unigramCost</code> is a function that takes in
    a single string representing a word and outputs its unigram cost.

    The function <code>segmentWords</code> should return the segmented
    sentence with spaces as delimiters, i.e. <code>' '.join(words)</code>.
  </p>
  <p>
    For convenience, you can actually run <code>python
    submission.py</code> to enter a console in which you can type
    character sequences that will be segmented by your implementation
    of <code>segmentWords</code>.  To request a segmentation,
    type <code>seg mystring</code> into the prompt.  For example:
    <pre>
      >> seg thisisnotmybeautifulhouse

        Query (seg): thisisnotmybeautifulhouse

        this is not my beautiful house
    </pre>
    Console commands other than <code>seg</code> &mdash;
    namely <code>ins</code> and <code>both</code> &mdash; will be used for
    the upcoming parts of the assignment.  Other commands that might
    help with debugging can be found by typing <code>help</code> at
    the prompt.
  </p>
</li>

</ol>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 2: vowel insertion</div>

<p>
  Now you are given a sequence of English words with their vowels
  missing (A, E, I, O, and U; never Y).  Your task is to place vowels
  back into these words in a way that maximizes sentence fluency
  (i.e., that minimizes sentence cost).  For this task, you will use a
  bigram cost function.
</p>
<p>
  You are also given a mapping <code>possibleFills</code> that maps
  any vowel-free word to a set of possible reconstructions (complete
  words).<sup><a href="#fn-6">[6]</a></sup> For
  example, <code>possibleFills('fg')</code>
  returns <code>set(['fugue', 'fog'])</code>.
</p>

<ol class="problem">

<li class="writeup">
  <p>
  Consider the following greedy-algorithm: from left to right, repeatedly pick the immediate-best (according to bigram cost) vowel insertion for the current vowel-free word given the insertion for the previous (i.e., not taking into account future insertions).
  </p>
  <p>
  Show, as in question 1, that this greedy algorithm is suboptimal, by providing a realistic counter-example using English text. Make any assumptions you'd like about possibleFills and the bigram cost function, but bigram costs must remain positive.
  </p>
</li>

<li class="code">
  <p>
    Implement an algorithm that finds optimal vowel insertions.  Use
    the UCS subroutines.
  </p>
  <p>
    When you've completed your implementation, the
    function <code>insertVowels</code> should return the reconstructed
    word sequence as a string with space delimiters, i.e.
    <code>' '.join(filledWords)</code>.
  </p>
  <p>
    The argument <code>queryWords</code> is the input sequence of
    vowel-free words.  Note well that the empty string is a valid such
    word.  The argument <code>bigramCost</code> is a function that
    takes two strings representing two sequential words and provides
    their bigram score.  The special out-of-vocabulary
    beginning-of-sentence word <code>-BEGIN-</code> is given
    by <code>wordsegUtil.SENTENCE_BEGIN</code>.  The
    argument <code>possibleFills</code> is a function; it takes a word
    as string and returns a <code>set</code> of
    reconstructions.
  </p>
  <p>
    <b>Note:</b> If some vowel-free word $w$
    has no reconstructions according to <code>possibleFills</code>,
    your implementation should consider $w$ itself as the sole
    possible reconstruction.
  </p>
  <p>
    Use the <code>ins</code> command in the program console to try
    your implementation.  For example:
    <pre>
      >> ins thts m n th crnr

        Query (ins): thts m n th crnr

        thats me in the corner
    </pre>
    The console strips away any vowels you do insert, so you can
    actually type in plain English and the vowel-free query will be
    issued to your program.  This also means that you can use a single
    vowel letter as a means to place an empty string in the sequence.
    For example:
    <pre>
      >> ins its a beautiful day in the neighborhood

        Query (ins): ts  btfl dy n th nghbrhd

        its a beautiful day in the neighborhood
    </pre>
  </p>
</li>

</ol>

<!------------------------------------------------------------>
<div class="problemTitle">Problem 3: putting it together</div>

<p>
  We'll now see that it's possible to solve both of these tasks at
  once.  This time, you are given a whitespace- and vowel-free string
  of alphabetical characters.  Your goal is to insert spaces and
  vowels into this string such that the result is the most fluent
  possible one.  As in the previous task, costs are based on a bigram
  cost function.
</p>

<ol class="problem">

<li class="writeup">
  <p> Consider a search problem for finding the optimal space and vowel insertions. Formalize the problem as a search problem, that is, what are the states, actions, costs, initial state, and goal test? Try to find a minimal representation of the states. 
  </p>

</li>

<li class="code">
  <p>
    Implement an algorithm that finds the optimal space and
    vowel insertions.  Use the UCS subroutines.
  </p>
  <p>
    When you've completed your implementation, the
    function <code>segmentAndInsert</code> should return a segmented
    and reconstructed word sequence as a string with space delimiters,
    i.e. <code>' '.join(filledWords)</code>.
  </p>
  <p>
    The argument <code>query</code> is the input string of space- and
    vowel-free words.  The argument <code>bigramCost</code> is a
    function that takes two strings representing two sequential words
    and provides their bigram score.  The special out-of-vocabulary
    beginning-of-sentence word <code>-BEGIN-</code> is given
    by <code>wordsegUtil.SENTENCE_BEGIN</code>.  The
    argument <code>possibleFills</code> is a function; it takes a word
    as string and returns a <code>set</code> of reconstructions.
  </p>
  <p>
    <b>Note:</b> Unlike in problem 2, where a vowel-free word
    could (under certain circumstances) be considered a valid
    reconstruction of itself, here you should never include in your
    output a word that is not the reconstruction of some vowel-free
    word according to <code>possibleFills</code>.  Additionally, you should not include all vowel words such as "a" or "I"; all words should include at least one consonant from the input string.
  </p>
  <p>
    Use the command <code>both</code> in the program console to try
    your implementation.  For example:
    <pre>
      >> both mgnllthppl

        Query (both): mgnllthppl

        imagine all the people
    </pre>
  </p>
</li>

<li class="writeup">
Let's find a way to speed up joint space and vowel insertion with A*.
Recall that having to score an output using a bigram model $b(w', w)$
is more expensive than using a unigram model $u(w)$ because we have to remember
the previous word $w'$ in the state.
Given $b(w',w)$, define $u(w)$ based on $b(w', w)$, define
a heuristic $h_u$ based on solving a simpler minimum cost path problem with $u$,
and prove that $h_u(s)$ is consistent.
In your description, you must be explicit about which search problem (the
original or the simpler one) you are referring to and what the states are.
</li>

</ol>

<hr/>
<p id="fn-1"> [1]
  In German, <i>Windschutzscheibenwischer</i> is "windshield wiper".
  Broken into parts: <i>wind</i> ~ wind; <i>schutz</i> ~ block /
  protection; <i>scheiben</i> ~ panes; <i>wischer</i> ~ wiper.
</p>
<p id="fn-2"> [2]
  See <a href="https://en.wikipedia.org/wiki/Abjad">https://en.wikipedia.org/wiki/Abjad</a>.
</p>
<p id="fn-3"> [3]
  This model works under the assumption that text roughly satisfies
  the <a href="https://en.wikipedia.org/wiki/Markov_property">Markov
  property</a>.
</p>
<p id="fn-4"> [4]
  Modulo edge cases, the $n$-gram model score in this assignment is
  given by $\ell(w_1, \ldots, w_n) = -\log(p(w_n \mid w_1, \ldots,
  w_{n-1}))$.  Here, $p(\cdot)$ is an estimate of the conditional
  probability distribution over words given the sequence of previous
  $n-1$ words.  This estimate is gathered from frequency counts taken
  by reading Leo Tolstoy's <i>War and Peace</i> and William
  Shakespeare's <i>Romeo and Juliet</i>.
</p>
<p id="fn-5"> [5]
  Solutions that use UCS ought to exhibit fairly fast execution time
  for this problem, so using A* here is unnecessary.
</p>
<p id="fn-6"> [6]
  This mapping, too, was obtained by reading Tolstoy and Shakespeare
  and removing vowels.
</p>

</body>
